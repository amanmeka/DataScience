{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amanmeka/DataScience/blob/main/Unit2/Aman_U2ExercisesSF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Unit 2 Exercises: Bayesian Building Blocks\n",
        "\n",
        "This first set of exercises focuses on conceptual understanding of the three parts of bayesian statistics we'll manipulate the most: the prior, likelihood, and posterior.\n",
        "\n",
        "These vocabulary words will help us categorize and explain all statistical models, even models that don't fit inside the standard bayesian framework."
      ],
      "metadata": {
        "id": "0GANUQSIhV2t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task1**:\n",
        "\n",
        "Why do we make guesses? In other words, what is the benefit of trying to predict something we are uncertain about?"
      ],
      "metadata": {
        "id": "4HnMLojUPtOR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "I think that the main reason that we make guesses is so that we can predict the future. For example, if you can predict the weather, then you can plan things accordingly. Or if you look at health data, you might be able to predict certain ailments. Also, similarly to the notes where we predicted whether or not Victor Wembanyama would make a shot or not, guessing using data science can be used for a variety of sports related things. For example, I have seen match predictors, which most likely employ data science to get a fair estimate of who will win the game.\n",
        "\n",
        "The benefit of trying to predict something we are uncertain about is that you can isolate specific cases. Specifically in healthcare, some people use data science to predict whether or not a person has cancer. By singling out the margin of people that may have cancer, they can reduce the number of people that actually get checked for the cancer."
      ],
      "metadata": {
        "id": "mDaA1AeLU5dU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task2**:\n",
        "\n",
        "Is is it possible to make a guess/prediction without making an assumption?\n",
        "\n",
        "If yes, then give an example of such a guess, and state whenever that guess would be useful or not.\n",
        "\n",
        "If no, then briefly justify why we need assumptions to make predictions."
      ],
      "metadata": {
        "id": "fMU4F4ZGQqb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "It is possible to make a guess without an assumption but, I don't think that it is possible to make a strong guess without assumptions. Assumptions are what we build our guess off of and without the supplement of an assumption, we would have to make baseless guesses, which are not strong. The first step of making a good guess is to make an assumption because then we can derive inferences (guesses with observation) from them."
      ],
      "metadata": {
        "id": "JuBQVSQ0U-cD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task3**:\n",
        "\n",
        "Should we use all the available information we have to make a guess/prediction? Justify your answer."
      ],
      "metadata": {
        "id": "8iIogaaJQEfl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "No, I don't think that using all the data available for making a guess/prediction is a good practice because if you use any available information you have, then your data will be distorted. For example, if you have information about a patient's favorite tv show, you shouldn't be using that to predict if they have cancer. Using irrelevant data will make the output of the prediction model to be more inaccurate then it was before. Therefore, it is only viable to use data that is relevant and strengthens the model."
      ],
      "metadata": {
        "id": "v8zljy-5QXSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task4**:\n",
        "\n",
        "What is a prior? How are priors related to\n",
        "- context?\n",
        "- assumptions?\n",
        "- predictions?"
      ],
      "metadata": {
        "id": "TYwtd8lPRFbj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "Priors are the initial beliefs when encountering a new \"problem\". Prior is similar to assumptions because assumptions are also like the initial beliefs that are established. You also establish your assumptions based on the context that is provided. For example, in the case of the Wembanyama prediction model, the number of shots that he made in the euroleague would count as context. We then made some assumptions using this data. The predictions are made based off of the context and assumptions but using the distribution methods. They are the same thing as context."
      ],
      "metadata": {
        "id": "d6vRRh3wVE5v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task5**:\n",
        "\n",
        "What is a likelihood? How are likelihoods related to:\n",
        "\n",
        "- context?\n",
        "- assumptions?\n",
        "- predictions?"
      ],
      "metadata": {
        "id": "v6NnzoV_RWo6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "In my own definition, I think that likelihood is the chance of a certain thing happening. You can approximate the likelihood of something happening with prior context (the data). With a big enough data set, it is possible to get the likelihood of the prediction model pretty high. The likelihood in prediction models is like the accuracy or the percentage that will be predicted right. Our assumptions are informed by the context. For example if we assumed that the euroleague hoops were the exact same size as the nba hoops (which they probably are but bear with me) then we would choose to use the data from the euroleague for predicting the percentage in the NBA. We choose to include that into our \"likelihood\". The likelihood is like how correct our prediction is. Or another way of thinking of it is how well the model explains the observed data."
      ],
      "metadata": {
        "id": "VK5s3vZpVGLc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task6**:\n",
        "\n",
        "What is a posterior? How are posteriors related to:\n",
        "\n",
        "- context?\n",
        "- assumptions?\n",
        "- predictions?"
      ],
      "metadata": {
        "id": "eYSYtG_2Rowf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "A posterior probability in simple terms is just the result of the prior probability given test data/evidence. In this case the equation would look something like this:\n",
        "\n",
        "$Prior * Test\\ Evidence = Posterior$\n",
        "\n",
        "In our \"cancer\" example from above, lets say that $p(c) = 0.01$, where c is cancer. Then let's say that $p(Ψ|c) = 0.9$, where Ψ (chose this because it looks cool) is if they test positive for cancer. The last equation reads: \"the probability of a positive given that there is cancer\".\n",
        "\n",
        "In that case, the posterior is: $p(c|Ψ) = p(c) * p(Ψ|c)$. There is actually a second case but that's just the opposite (where instead of c it's c not).\n",
        "\n",
        "Looking at the equations, it is easy to tell that the posterior defines the actual truth in the world. the posterior is equal to the probability of cancer given that it is positive (this relates the real truth and not just possibility). We can also tell that assumptions are used to make final predictions when given the posterior. It is also important to use context and assumptions from the likelihood (above) when making a final prediction.\n",
        "\n",
        "More summarized version is that a posterior makes a prediction using the observed data (the context) and you make assumptions from the observed data.\n",
        "\n"
      ],
      "metadata": {
        "id": "T04x1VteVHH1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task7**:\n",
        "\n",
        "Why would anyone want to define a prior and a likelihood in order to make a prediction? In other words, what's the point of using a likelihood and a prior to form a posterior?"
      ],
      "metadata": {
        "id": "CMAm4LqBXYxG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "Because if you use a prior and a likelihood, you can make more informed decisions about your prediction. The prior is the initial beliefs that you have before you get any data and the likelihood is essentially a graphical representation of each possible success count. so when given a prior and a likelihood you can make a more informed prediction. helps you update your belief about a prediction.\n"
      ],
      "metadata": {
        "id": "rag62h9DVIDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bayes' Rule Math\n",
        "\n",
        "The following exercises will be graded for completion, with no accuracy component. That said, correct answers below will replace mistakes in tasks 1-7.\n",
        "\n"
      ],
      "metadata": {
        "id": "BNrO2k34SGoF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mathematical Framing\n",
        "\n",
        "In this series of exercises, we'll calculate a probability using the full version of Bayes' Rule.\n",
        "\n",
        "The version seen in the notes, $p(θ|y) ∝ p(y|θ)p(θ)$, ignores the normalizing constant found in the full equation: $p(θ|y) = \\frac{p(y|θ)p(θ)}{p(y)}$.\n",
        "\n",
        "As stated in the notes, in practical applications we don't need to worry too much about $p(y)$, AKA the marginal likelihood, AKA the prior predictive density, AKA the normalizing constant. And when we do, we'll approximate like we do everything else.\n",
        "\n",
        "The following exercises are closer to theoretical abstraction, rather than practicality.\n",
        "\n",
        "So why do them?\n",
        "\n",
        "These exercises will (hopefully) help you gain additional intuition for probability, and how it behaves.\n",
        "\n",
        "As you work through the exercises, consider $p(y)$, the  prior predictive density, and why using it to divide $p(y|θ)p(θ)$ gurantees that we get a probability.\n",
        "\n",
        "Additonaly, wonder about:\n",
        "- the likelihood $p(y|θ)$\n",
        "- the prior $p(θ)$,\n",
        "- why multiplying the likelihood and piror *almost* gives us the posterior $p(θ|y)$."
      ],
      "metadata": {
        "id": "w7KMRJa_TmdF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Problem Setting\n",
        "\n",
        "Imagine we have a bag of red and white marbles, identical in every other way. Each individual marble is either entirely white or entirely red.\n",
        "\n",
        "Let's assume there are 4 total marbles, that we can't see inside the bag, and when we grab a ball from the bag, we replace it and shake the bag to scramble the balls.\n",
        "\n",
        "Additionally:\n",
        "\n",
        "- we draw three balls in this order: red-white-red. Call these the data, $y$. Remember, we replaced the ball and shook the bag between each draw.\n",
        "- we are interested in finding the true proportion of red balls in the bag, called $θ$"
      ],
      "metadata": {
        "id": "ab7E9RIuj2OX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task8**:\n",
        "\n",
        "Write out all the possible color compositions of the marbles in the bag, before we observed our data $y$ (which are the marbles drawn in the order of red-white-red).\n",
        "\n",
        "Let each of these possible color compositions be a possible $θ$, or true proportion of red marbles."
      ],
      "metadata": {
        "id": "AmHTGWQQHuAD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "the compositions are:\n",
        "RRRR\n",
        "RRRW\n",
        "RRWW\n",
        "RWWW\n",
        "WWWW\n",
        "\n",
        "---\n",
        "\n",
        "all the possible combinations are:\n",
        "RRRR\n",
        "RRRW\n",
        "RRWR\n",
        "RRWW\n",
        "RWRR\n",
        "RWRW\n",
        "RWWR\n",
        "RWWW\n",
        "WRRR\n",
        "WRRW\n",
        "WRWR\n",
        "WRWW\n",
        "WWRR\n",
        "WWRW\n",
        "WWWR\n",
        "WWWW"
      ],
      "metadata": {
        "id": "EkPylHwCVK72"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task9**:\n",
        "\n",
        "Which color compositions are possible after seeing the data $y$?"
      ],
      "metadata": {
        "id": "-TELvcnVH8N2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "the compositions are:\n",
        "RRRR\n",
        "RRRW\n",
        "RRWW\n",
        "RWWW\n",
        "WWWW\n",
        "\n",
        "---\n",
        "\n",
        "all the possible combinations are:\n",
        "RRRW\n",
        "RRWR\n",
        "RRWW\n",
        "RWRR\n",
        "RWRW\n",
        "RWWR\n",
        "WRRR\n",
        "WRRW\n",
        "WRWR\n",
        "WWRR"
      ],
      "metadata": {
        "id": "7q6nUOdNMN9Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task10**:\n",
        "\n",
        "How many ways can you select red-white-red, assuming that there are 2 red marbles and 2 white marbles?"
      ],
      "metadata": {
        "id": "vIjecZm7OVcy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "All the possible ways that you select red white red is listed below (number next to color describes which ball):\n",
        "\n",
        "\n",
        "*   red1 white1 red1\n",
        "*   red1 white1 red2\n",
        "*   red1 white2 red1\n",
        "*   red1 white2 red2\n",
        "*   red2 white1 red1\n",
        "*   red2 white1 red2\n",
        "*   red2 white2 red1\n",
        "*   red2 white2 red2"
      ],
      "metadata": {
        "id": "CLLiTDms5VHj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task11**:\n",
        "\n",
        "How many different ways can you select three balls so that order matters, given that there are 2 red marbles and 2 white marbles?"
      ],
      "metadata": {
        "id": "Bs7tx0pXhUZy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "The different possibilities for selection of three balls so that order matters and so that there are 2 red and 2 white marbles is:\n",
        "*   RRR\n",
        "*   RRW\n",
        "*   RWR\n",
        "*   RWW\n",
        "*   WRR\n",
        "*   WRW\n",
        "*   WWR\n",
        "*   WWW\n",
        "\n",
        "and then there are 8 different ways to pick each of the color combinations as proved in Task 10 so 8 * 8 is 64 so there are 64 ways to pick out three balls so that order matters (order of the marbles)."
      ],
      "metadata": {
        "id": "69ScN4NYh6ks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task12**:\n",
        "\n",
        "What's the probablity you select red-white-red, given that there are 2 red marbles and 2 white marbles?\n",
        "\n",
        "Stated differently,\n",
        "\n",
        "Find the likelihood $p(y|θ)$, where $θ=RRWW$"
      ],
      "metadata": {
        "id": "k87Z69qUg9KV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "there are 1/2 odds that you choose on of the red marbles. also 1/2 odds that you choose one of the white marbles. and another 1/2 odds that you choose one of the red marbles at the end.\n",
        "\n",
        "$p(y|RRWW) = p(R) * p(W) * p(R) = \\frac{1}{2} * \\frac{1}{2} * \\frac{1}{2} = \\frac{1}{8}$\n",
        "\n",
        "so in total the odds are $\\frac{1}{8}$ odds."
      ],
      "metadata": {
        "id": "v5bdqu1nri3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task13**\n",
        "\n",
        "If--before seeing the data--all color compostions are equally likely,\n",
        "\n",
        "then what is $p(\\theta)$, if $\\theta = RRWW$?"
      ],
      "metadata": {
        "id": "_rZSSoR8NbEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "The color compositions are:\n",
        "\n",
        "RRRR\n",
        "\n",
        "RRRW\n",
        "\n",
        "RRWW\n",
        "\n",
        "RWWW\n",
        "\n",
        "WWWW\n",
        "\n",
        "so the chance of getting a RRWW color composition is 1/5 because RRWW is one out of the five. so the odds are 1/5."
      ],
      "metadata": {
        "id": "N3PVjOk5wDZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task14**:\n",
        "\n",
        "Find:\n",
        "\n",
        "- $p(y|WWWW)$\n",
        "- $p(y|RWWW)$\n",
        "- $p(y|RRWW)$\n",
        "- $p(y|RRRW)$\n",
        "- $p(y|RRRR)$"
      ],
      "metadata": {
        "id": "j6e9WP49sZJh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "y = RWR\n",
        "*   $p(y|WWWW) = p(R) * p(W) * p(R) = 0 × 1 × 0 = 0$, because there no reds in the WWWW to pull from, there are no reds to pull for the RWR (data).\n",
        "*   $p(y|RWWW) = p(R) * p(W) * p(R) = \\frac{1}{4} * \\frac{3}{4} * \\frac{1}{4} = \\frac{3}{64}$\n",
        "*   $p(y|RRWW) = p(R) * p(W) * p(R) = \\frac{1}{2} * \\frac{1}{2} * \\frac{1}{2} = \\frac{1}{8}$\n",
        "*   $p(y|RRRW) = p(R) * p(W) * p(R) = \\frac{3}{4} * \\frac{1}{4} * \\frac{3}{4} = \\frac{9}{64}$\n",
        "*   $p(y|RRRR) = p(R) * p(W) * p(R) = 1 × 0 × 1 = 0$, because there no whites in the RRRR to pull from, there are no whites to pull for the RWR (data).\n",
        "\n"
      ],
      "metadata": {
        "id": "NbSC4dj_tf4Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task15**\n",
        "\n",
        "Assume that each color compostions is equally likely before seeing the data.\n",
        "\n",
        "Find:\n",
        "\n",
        "- $p(y|WWWW)p(WWWW)$\n",
        "- $p(y|RWWW)p(RWWW)$\n",
        "- $p(y|RRWW)p(RRWW)$\n",
        "- $p(y|RRRW)p(RRRW)$\n",
        "- $p(y|RRRR)p(RRRR)$\n"
      ],
      "metadata": {
        "id": "W6f3Ll2oWmMJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "y = RWR\n",
        "*   $p(y|WWWW)p(WWWW) = p(R) * p(W) * p(R) = 0 × 1 × 0 × \\frac{1}{5} = 0$, because there no reds in the WWWW to pull from, there are no reds to pull for the RWR (data).\n",
        "\n",
        "*   $p(y|RWWW)p(RWWW) = p(R) * p(W) * p(R) * p(RWWW) = \\frac{1}{4} * \\frac{3}{4} * \\frac{1}{4} * \\frac{1}{5} = \\frac{3}{320}$\n",
        "\n",
        "*   $p(y|RRWW)p(RRWW) = p(R) * p(W) * p(R) * p(RRWW) = \\frac{1}{2} * \\frac{1}{2} * \\frac{1}{2} * \\frac{1}{5} = \\frac{1}{40}$\n",
        "\n",
        "*   $p(y|RRRW)p(RRRW) = p(R) * p(W) * p(R) * p(RRRW) = \\frac{3}{4} * \\frac{1}{4} * \\frac{3}{4} * \\frac{1}{5} = \\frac{9}{320}$\n",
        "\n",
        "*   $p(y|RRRR)p(RRRR) = p(R) * p(W) * p(R) = 1 × 0 × 1 × \\frac{1}{5}= 0$, because there no whites in the RRRR to pull from, there are no whites to pull for the RWR (data).\n",
        "\n"
      ],
      "metadata": {
        "id": "t_TZsERtXMQu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task16**:\n",
        "\n",
        "Find the probablity of getting red-white-red, $p(y)$, given each possible color combination is equally likely."
      ],
      "metadata": {
        "id": "qxSVk_Sjv8Gk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "The probability of getting red-white-red or $p(y)$ is the sum of all of the possibilities in the last one so:\n",
        "\n",
        "$\\frac{3}{320} + \\frac{9}{320} + \\frac{8}{320} = \\frac{20}{320}$ which is the same as $\\frac{1}{16}$"
      ],
      "metadata": {
        "id": "641kAEFkOK8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task17**:\n",
        "\n",
        "After observing a draw of red-white-red, find the probability that there are two red marbles and two white marbles in the bag. Assume that all color compositions were equally likely before the draw.\n",
        "\n",
        "In other words, find $p(θ|y)$, where $θ=RRWW$."
      ],
      "metadata": {
        "id": "CYoWtEwxyNB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "So the probability of $p(θ|y)$ where $θ = RRWW$ is pretty simple.\n",
        "\n",
        "The answer is $\\frac{1}{3}$. this is because we already know that there has to be atleast one red and one white.\n",
        "\n",
        "So given the data there are three possible color compositions:\n",
        "\n",
        "* RWWW\n",
        "* RRWW\n",
        "* RRRW\n",
        "\n",
        "and because it says that each color composition is equally likely we can settle with a $\\frac{1}{3}$ chance of the color composition being RRWW."
      ],
      "metadata": {
        "id": "WxX-o3Uuy9eR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task18**:\n",
        "\n",
        "Story time: The marble factory produces bags of four marbles. They want to make red marbles rare, so that people will get excited about them.  Therefore, for each 1 bag containing four red, they made 2 that contain three red, 3 that contain two red, 4 that contain one red, and 5 that contain zero red.\n",
        "\n",
        "With this new prior information, find $p(θ|y)$, where $θ=RRWW$.\n",
        "\n",
        "**NOTE**: You MUST calculate  a new marginal likelihood $p(y)$ with the new prior information."
      ],
      "metadata": {
        "id": "VgMdbaKW1o39"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "This is similar to the last question but we need to assign weightages to each of the likely color compositions.\n",
        "\n",
        "So to find $p(θ|y)$, where $θ$ = RRWW, all we need to do is to take the three possible outcomes of color compositions given the data, y, and assign weightages.\n",
        "\n",
        "So in total there are $1 + 2 + 3 + 4 + 5$ bags which is equal to $15$.\n",
        "\n",
        "* RWWW $= 4$\n",
        "* RRWW $= 3$ (this is the one we want to find the probability for)\n",
        "* RRRW $= 2$\n",
        "\n",
        "Now to find RRWW's chance of being the color composition we take its weightage number, 3, and divide it by the added weightage numbers, 9.\n",
        "\n",
        "So the new probability of the color compositions with our new prior information is $\\frac{3}{9}$ or $\\frac{1}{3}$."
      ],
      "metadata": {
        "id": "UMMrUAIs3Dsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task19**:\n",
        "\n",
        "Write down similarities and differences between this marble example, and the VIctor Wembanyama FT example."
      ],
      "metadata": {
        "id": "ABn_s24K4K0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "one difference is that the FT example is more binary than the marble example. In the marble example, there are multiple different ways that something could happen. The FT example is either a make or a miss. Also the FT example is easier to model with a beta-binomial prediction model whereas the marble example is not possible to model with the prediction model discussed in the Unit 2 notes.\n",
        "\n",
        "One similarity between the marble example and the Wembanyama FT example is that they both use a prior to make a prediction and you can also make a predictive model for both of them because you are able to extract a probability out of each scenario in the marble example too."
      ],
      "metadata": {
        "id": "CAmT3Bd34fhc"
      }
    }
  ]
}